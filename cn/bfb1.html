<!DOCTYPE html><html lang="zh-Hans"><head><meta name="generator" content="Hexo 3.8.0"><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><meta name="theme-color" content="#f8f5ec"><meta name="msapplication-navbutton-color" content="#f8f5ec"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-status-bar-style" content="#f8f5ec"><meta name="referrer" content="same-origin"><meta name="referrer" content="no-referrer"><meta name="description" content="SparkSQL基本操作"><meta name="keywords" content="大数据,BigData,数据开发,BI,数据分析,Hadoop,Spark,Flink,Hive,HBase"><link rel="alternate" href="/cn/atom.xml" title="马攀的技术栈"><link rel="shortcut icon" type="image/x-icon" href="/cn/favicon.ico?v=2.11.0"><link rel="canonical" href="https://mapan.tech/cn/bfb1.html"><link rel="stylesheet" type="text/css" href="/cn/css/style.css?v=2.11.0"><script id="baidu_analytics">var _hmt=_hmt||[];!function(){var e=document.createElement("script");e.src="https://hm.baidu.com/hm.js?8a2255104fa5226d5e9ee3e7519e7ade";var t=document.getElementsByTagName("script")[0];t.parentNode.insertBefore(e,t)}()</script><script id="baidu_push">!function(){var t=document.createElement("script"),s=window.location.protocol.split(":")[0];"https"===s?t.src="https://zz.bdstatic.com/linksubmit/push.js":t.src="http://push.zhanzhang.baidu.com/push.js";var e=document.getElementsByTagName("script")[0];e.parentNode.insertBefore(t,e)}()</script><script>window.config={toc:!0,fancybox:!1,pjax:!1,latex:!1}</script><title>SparkSQL基本操作 - 马攀的技术栈</title></head><body><div id="mobile-navbar" class="mobile-navbar"><div class="mobile-header-logo"><a href="/cn/." class="logo">马攀的技术栈</a></div><div class="mobile-navbar-icon"><span></span> <span></span> <span></span></div></div><nav id="mobile-menu" class="mobile-menu slideout-menu"><ul class="mobile-menu-list"><a href="/cn/"><li class="mobile-menu-item">首页</li></a><a href="/cn/categories.html"><li class="mobile-menu-item">分类</li></a><a href="/cn/about.html"><li class="mobile-menu-item">关于</li></a><a href="/cn/message.html"><li class="mobile-menu-item">留言</li></a><a href="/cn/links.html"><li class="mobile-menu-item">友链</li></a></ul></nav><div class="container" id="mobile-panel"><header id="header" class="header"><div class="logo-wrapper"><a href="https://mapan.tech" class="logo">马攀的技术栈</a></div><nav class="site-navbar"><ul id="menu" class="menu"><li class="menu-item"><a class="menu-item-link" href="/cn/">首页</a></li><li class="menu-item"><a class="menu-item-link" href="/cn/categories.html">分类</a></li><li class="menu-item"><a class="menu-item-link" href="/cn/about.html">关于</a></li><li class="menu-item"><a class="menu-item-link" href="/cn/message.html">留言</a></li><li class="menu-item"><a class="menu-item-link" href="/cn/links.html">友链</a></li></ul></nav></header><main id="main" class="main"><div class="content-wrapper"><div id="content" class="content"><article class="post"><header class="post-header"><h1 class="post-title">SparkSQL基本操作</h1><div class="post-meta"><span class="post-time">2018-08-20 </span><span class="post-category"><a href="/cn/categories/Spark/">Spark</a> </span><span id="/cn/bfb1.html" class="leancloud-visitors" data-flag-title="SparkSQL基本操作">阅读数 <span class="leancloud-visitors-count">1000</span> </span><span class="post-count">字数统计 1.1k </span><span class="post-count">阅读时长 5</span></div></header><div class="post-toc" id="post-toc"><h2 class="post-toc-title">文章目录</h2><div class="post-toc-content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#创建DataFrame"><span class="toc-text">创建DataFrame</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#方法一-RDDtoDF创建DataFrame"><span class="toc-text">方法一: RDDtoDF创建DataFrame</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#方法二-样例类转DataFrame-常用方式"><span class="toc-text">方法二 : 样例类转DataFrame(常用方式)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#方法三-通过schema创建DataFrame"><span class="toc-text">方法三: 通过schema创建DataFrame</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#创建DataSet"><span class="toc-text">创建DataSet</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#通过样例类创建DataSet"><span class="toc-text">通过样例类创建DataSet</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#从RDD创建DataSet"><span class="toc-text">从RDD创建DataSet</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#DataFrame与DataSet的互相转换"><span class="toc-text">DataFrame与DataSet的互相转换</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#DataFreame转DataSet"><span class="toc-text">DataFreame转DataSet</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#DasaSet转DataFrame"><span class="toc-text">DasaSet转DataFrame</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#三者的互相转换"><span class="toc-text">三者的互相转换</span></a></li></ol></div></div><div class="post-content"><p>首先进入spark-shell<br></p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">$ bin/spark-shell</span><br><span class="line"><span class="type">Using</span> <span class="type">Spark</span><span class="symbol">'s</span> <span class="keyword">default</span> log4j profile: org/apache/spark/log4j-defaults.properties</span><br><span class="line"><span class="type">Setting</span> <span class="keyword">default</span> log level to <span class="string">"WARN"</span>.</span><br><span class="line"><span class="type">To</span> adjust logging level use sc.setLogLevel(newLevel). <span class="type">For</span> <span class="type">SparkR</span>, use setLogLevel(newLevel).</span><br><span class="line"><span class="type">Spark</span> context <span class="type">Web</span> <span class="type">UI</span> available at http:<span class="comment">//192.168.1.102:4040</span></span><br><span class="line"><span class="type">Spark</span> context available as <span class="symbol">'s</span>c' (master = local[*], app id = local<span class="number">-1569915192693</span>).</span><br><span class="line"><span class="type">Spark</span> session available as <span class="symbol">'spar</span>k'.</span><br><span class="line"><span class="type">Welcome</span> to</span><br><span class="line">      ____              __</span><br><span class="line">     / __/__  ___ _____/ /__</span><br><span class="line">    _\ \/ _ \/ _ `/ __/  <span class="symbol">'_</span>/</span><br><span class="line">   /___/ .__/\_,_/_/ /_/\_\   version <span class="number">2.1</span><span class="number">.1</span></span><br><span class="line">      /_/</span><br><span class="line">         </span><br><span class="line"><span class="type">Using</span> <span class="type">Scala</span> version <span class="number">2.11</span><span class="number">.8</span> (<span class="type">Java</span> <span class="type">HotSpot</span>(<span class="type">TM</span>) <span class="number">64</span>-<span class="type">Bit</span> <span class="type">Server</span> <span class="type">VM</span>, <span class="type">Java</span> <span class="number">1.8</span><span class="number">.0</span>_144)</span><br><span class="line"><span class="type">Type</span> in expressions to have them evaluated.</span><br><span class="line"><span class="type">Type</span> :help <span class="keyword">for</span> more information.</span><br></pre></td></tr></table></figure><p></p><h2 id="创建DataFrame"><a href="#创建DataFrame" class="headerlink" title="创建DataFrame"></a>创建DataFrame</h2><ul><li>从json文件中创建DataFrame</li></ul><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; <span class="keyword">val</span> df = spark.read.json(<span class="string">"./examples/src/main/resources/people.json"</span>)</span><br><span class="line">df: org.apache.spark.sql.<span class="type">DataFrame</span> = [age: bigint, name: string]</span><br><span class="line"></span><br><span class="line">scala&gt; df.show</span><br><span class="line">+----+-------+</span><br><span class="line">| age|   name|</span><br><span class="line">+----+-------+</span><br><span class="line">|<span class="literal">null</span>|<span class="type">Michael</span>|</span><br><span class="line">|  <span class="number">30</span>|   <span class="type">Andy</span>|</span><br><span class="line">|  <span class="number">19</span>| <span class="type">Justin</span>|</span><br><span class="line">+----+-------+</span><br></pre></td></tr></table></figure><ul><li>对DataFrame创建一个临时表</li></ul><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; df.createOrReplaceTempView(<span class="string">"people"</span>)</span><br><span class="line">scala&gt; spark.sql(<span class="string">"select * from people"</span>).show</span><br><span class="line">+----+-------+</span><br><span class="line">| age|   name|</span><br><span class="line">+----+-------+</span><br><span class="line">|<span class="literal">null</span>|<span class="type">Michael</span>|</span><br><span class="line">|  <span class="number">30</span>|   <span class="type">Andy</span>|</span><br><span class="line">|  <span class="number">19</span>| <span class="type">Justin</span>|</span><br><span class="line">+----+-------+</span><br></pre></td></tr></table></figure><h2 id="方法一-RDDtoDF创建DataFrame"><a href="#方法一-RDDtoDF创建DataFrame" class="headerlink" title="方法一: RDDtoDF创建DataFrame"></a>方法一: RDDtoDF创建DataFrame</h2><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; <span class="keyword">import</span> spark.implicits._</span><br><span class="line"><span class="keyword">import</span> spark.implicits._</span><br><span class="line"></span><br><span class="line">scala&gt; <span class="keyword">val</span> peopleRDD = sc.textFile(<span class="string">"./examples/src/main/resources/people.txt"</span>)</span><br><span class="line">peopleRDD: org.apache.spark.rdd.<span class="type">RDD</span>[<span class="type">String</span>] = ./examples/src/main/resources/people.txt <span class="type">MapPartitionsRDD</span>[<span class="number">34</span>] at textFile at &lt;console&gt;:<span class="number">27</span></span><br><span class="line"></span><br><span class="line">scala&gt; <span class="keyword">val</span> df = peopleRDD.map&#123;x=&gt;<span class="keyword">val</span> para=x.split(<span class="string">","</span>);(para(<span class="number">0</span>),para(<span class="number">1</span>).trim.toInt)&#125;.toDF(<span class="string">"name"</span>,<span class="string">"age"</span>)</span><br><span class="line">df: org.apache.spark.sql.<span class="type">DataFrame</span> = [name: string, age: int]</span><br><span class="line"></span><br><span class="line">scala&gt; df.show</span><br><span class="line">+-------+---+</span><br><span class="line">|   name|age|</span><br><span class="line">+-------+---+</span><br><span class="line">|<span class="type">Michael</span>| <span class="number">29</span>|</span><br><span class="line">|   <span class="type">Andy</span>| <span class="number">30</span>|</span><br><span class="line">| <span class="type">Justin</span>| <span class="number">19</span>|</span><br><span class="line">+-------+---+</span><br></pre></td></tr></table></figure><h3 id="方法二-样例类转DataFrame-常用方式"><a href="#方法二-样例类转DataFrame-常用方式" class="headerlink" title="方法二 : 样例类转DataFrame(常用方式)"></a>方法二 : 样例类转DataFrame(常用方式)</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; <span class="keyword">case</span> <span class="class"><span class="keyword">class</span> <span class="title">people</span>(<span class="params">name:<span class="type">String</span>,age:<span class="type">Int</span></span>)</span></span><br><span class="line"><span class="class"><span class="title">defined</span> <span class="title">class</span> <span class="title">people</span></span></span><br><span class="line"><span class="class"></span></span><br><span class="line"><span class="class"><span class="title">scala&gt;</span> <span class="title">peopleRDD</span>.<span class="title">map</span></span>&#123;x=&gt;<span class="keyword">val</span> para=x.split(<span class="string">","</span>);people(para(<span class="number">0</span>),para(<span class="number">1</span>).trim.toInt) &#125;.toDF</span><br><span class="line">res21: org.apache.spark.sql.<span class="type">DataFrame</span> = [name: string, age: int]</span><br></pre></td></tr></table></figure><h3 id="方法三-通过schema创建DataFrame"><a href="#方法三-通过schema创建DataFrame" class="headerlink" title="方法三: 通过schema创建DataFrame"></a>方法三: 通过schema创建DataFrame</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 导入所需的类型</span></span><br><span class="line">scala&gt; <span class="keyword">import</span> org.apache.spark.sql.types._</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.sql.types._</span><br><span class="line"><span class="comment">// 创建Schema</span></span><br><span class="line">scala&gt; <span class="keyword">val</span> structType: <span class="type">StructType</span> = <span class="type">StructType</span>(<span class="type">StructField</span>(<span class="string">"name"</span>, <span class="type">StringType</span>) :: <span class="type">StructField</span>(<span class="string">"age"</span>, <span class="type">IntegerType</span>) :: <span class="type">Nil</span>)</span><br><span class="line">structType: org.apache.spark.sql.types.<span class="type">StructType</span> = <span class="type">StructType</span>(<span class="type">StructField</span>(name,<span class="type">StringType</span>,<span class="literal">true</span>), <span class="type">StructField</span>(age,<span class="type">IntegerType</span>,<span class="literal">true</span>))</span><br><span class="line"><span class="comment">// 导入所需的类型</span></span><br><span class="line">scala&gt; <span class="keyword">import</span> org.apache.spark.sql.<span class="type">Row</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.sql.<span class="type">Row</span></span><br><span class="line"><span class="comment">// 根据给定的类型创建二元组RDD</span></span><br><span class="line">scala&gt; <span class="keyword">val</span> data = peopleRDD.map&#123; x =&gt; <span class="keyword">val</span> para = x.split(<span class="string">","</span>);<span class="type">Row</span>(para(<span class="number">0</span>),para(<span class="number">1</span>).trim.toInt)&#125;</span><br><span class="line">data: org.apache.spark.rdd.<span class="type">RDD</span>[org.apache.spark.sql.<span class="type">Row</span>] = <span class="type">MapPartitionsRDD</span>[<span class="number">41</span>] at map at &lt;console&gt;:<span class="number">33</span></span><br><span class="line"><span class="comment">// 根据数据及给定的schema创建DataFrame</span></span><br><span class="line">scala&gt; <span class="keyword">val</span> dataFrame = spark.createDataFrame(data, structType)</span><br><span class="line">dataFrame: org.apache.spark.sql.<span class="type">DataFrame</span> = [name: string, age: int]</span><br></pre></td></tr></table></figure><h2 id="创建DataSet"><a href="#创建DataSet" class="headerlink" title="创建DataSet"></a>创建DataSet</h2><h3 id="通过样例类创建DataSet"><a href="#通过样例类创建DataSet" class="headerlink" title="通过样例类创建DataSet"></a>通过样例类创建DataSet</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; <span class="keyword">case</span> <span class="class"><span class="keyword">class</span> <span class="title">Person</span>(<span class="params">name: <span class="type">String</span>, age: <span class="type">Long</span></span>)</span></span><br><span class="line"><span class="class"><span class="title">defined</span> <span class="title">class</span> <span class="title">Person</span></span></span><br><span class="line"><span class="class"></span></span><br><span class="line"><span class="class"><span class="title">scala&gt;</span> <span class="title">val</span> <span class="title">caseClassDS</span> </span>= <span class="type">Seq</span>(<span class="type">Person</span>(<span class="string">"Andy"</span>, <span class="number">32</span>)).toDS()</span><br><span class="line">caseClassDS: org.apache.spark.sql.<span class="type">Dataset</span>[<span class="type">Person</span>] = [name: string, age: bigint]</span><br><span class="line"></span><br><span class="line">scala&gt; caseClassDS.show</span><br><span class="line">+----+---+</span><br><span class="line">|name|age|</span><br><span class="line">+----+---+</span><br><span class="line">|<span class="type">Andy</span>| <span class="number">32</span>|</span><br><span class="line">+----+---+</span><br></pre></td></tr></table></figure><h3 id="从RDD创建DataSet"><a href="#从RDD创建DataSet" class="headerlink" title="从RDD创建DataSet"></a>从RDD创建DataSet</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; <span class="keyword">val</span> peopleRDD = sc.textFile(<span class="string">"examples/src/main/resources/people.txt"</span>)</span><br><span class="line">peopleRDD: org.apache.spark.rdd.<span class="type">RDD</span>[<span class="type">String</span>] = examples/src/main/resources/people.txt <span class="type">MapPartitionsRDD</span>[<span class="number">1</span>] at textFile at &lt;console&gt;:<span class="number">24</span></span><br><span class="line"></span><br><span class="line">scala&gt; peopleRDD.map(line =&gt; &#123;<span class="keyword">val</span> para = line.split(<span class="string">","</span>);<span class="type">Person</span>(para(<span class="number">0</span>),para(<span class="number">1</span>).trim.toInt)&#125;).toDS</span><br><span class="line">res1: org.apache.spark.sql.<span class="type">Dataset</span>[<span class="type">Person</span>] = [name: string, age: bigint]</span><br><span class="line"></span><br><span class="line">scala&gt; res1.show</span><br><span class="line">+-------+---+</span><br><span class="line">|   name|age|</span><br><span class="line">+-------+---+</span><br><span class="line">|<span class="type">Michael</span>| <span class="number">29</span>|</span><br><span class="line">|   <span class="type">Andy</span>| <span class="number">30</span>|</span><br><span class="line">| <span class="type">Justin</span>| <span class="number">19</span>|</span><br><span class="line">+-------+---+</span><br></pre></td></tr></table></figure><h2 id="DataFrame与DataSet的互相转换"><a href="#DataFrame与DataSet的互相转换" class="headerlink" title="DataFrame与DataSet的互相转换"></a>DataFrame与DataSet的互相转换</h2><h3 id="DataFreame转DataSet"><a href="#DataFreame转DataSet" class="headerlink" title="DataFreame转DataSet"></a>DataFreame转DataSet</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; <span class="keyword">val</span> df = spark.read.json(<span class="string">"examples/src/main/resources/people.json"</span>)</span><br><span class="line">df: org.apache.spark.sql.<span class="type">DataFrame</span> = [age: bigint, name: string]                </span><br><span class="line"></span><br><span class="line">scala&gt; <span class="keyword">case</span> <span class="class"><span class="keyword">class</span> <span class="title">Person</span>(<span class="params">name: <span class="type">String</span>, age: <span class="type">Long</span></span>)</span></span><br><span class="line"><span class="class"><span class="title">defined</span> <span class="title">class</span> <span class="title">Person</span></span></span><br><span class="line"><span class="class"></span></span><br><span class="line"><span class="class"><span class="title">scala&gt;</span> <span class="title">df</span>.<span class="title">as</span>[<span class="type">Person</span>]</span></span><br><span class="line"><span class="class"><span class="title">res3</span></span>: org.apache.spark.sql.<span class="type">Dataset</span>[<span class="type">Person</span>] = [age: bigint, name: string]</span><br><span class="line"></span><br><span class="line">scala&gt; res3.show</span><br><span class="line">+----+-------+</span><br><span class="line">| age|   name|</span><br><span class="line">+----+-------+</span><br><span class="line">|<span class="literal">null</span>|<span class="type">Michael</span>|</span><br><span class="line">|  <span class="number">30</span>|   <span class="type">Andy</span>|</span><br><span class="line">|  <span class="number">19</span>| <span class="type">Justin</span>|</span><br><span class="line">+----+-------+</span><br></pre></td></tr></table></figure><h3 id="DasaSet转DataFrame"><a href="#DasaSet转DataFrame" class="headerlink" title="DasaSet转DataFrame"></a>DasaSet转DataFrame</h3><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; <span class="keyword">case</span> <span class="class"><span class="keyword">class</span> <span class="title">Person</span>(<span class="params">name: <span class="type">String</span>, age: <span class="type">Long</span></span>)</span></span><br><span class="line"><span class="class"><span class="title">defined</span> <span class="title">class</span> <span class="title">Person</span></span></span><br><span class="line"><span class="class"></span></span><br><span class="line"><span class="class"><span class="title">scala&gt;</span> <span class="title">val</span> <span class="title">ds</span> </span>= <span class="type">Seq</span>(<span class="type">Person</span>(<span class="string">"Andy"</span>, <span class="number">32</span>)).toDS()</span><br><span class="line">ds: org.apache.spark.sql.<span class="type">Dataset</span>[<span class="type">Person</span>] = [name: string, age: bigint]</span><br><span class="line"></span><br><span class="line">scala&gt; <span class="keyword">val</span> df = ds.toDF</span><br><span class="line">df: org.apache.spark.sql.<span class="type">DataFrame</span> = [name: string, age: bigint]</span><br><span class="line"></span><br><span class="line">scala&gt; df.show</span><br><span class="line">+----+---+</span><br><span class="line">|name|age|</span><br><span class="line">+----+---+</span><br><span class="line">|<span class="type">Andy</span>| <span class="number">32</span>|</span><br><span class="line">+----+---+</span><br></pre></td></tr></table></figure><h2 id="三者的互相转换"><a href="#三者的互相转换" class="headerlink" title="三者的互相转换"></a>三者的互相转换</h2><p><img src="/cn/bfb1/1569984874237.png" alt="1569984874237"></p><p>三者的共性</p><ol><li><code>RDD</code>、<code>DataFrame</code>、<code>Dataset</code>全都是spark平台下的分布式弹性数据集，为处理超大型数据提供便利;</li><li>三者都有惰性机制，在进行创建、转换，如<code>map</code>方法时，不会立即执行，只有在遇到<code>Action</code>如<code>foreach</code>时，三者才会开始遍历运算;</li><li>三者有许多共同的函数，如filter，排序等;</li><li>在对<code>DataFrame</code>和<code>Dataset</code>进行操作许多操作都需要导入隐式转换 <code>:import spark.implicits._</code>（在创建好<code>SparkSession</code>对象后尽量直接导入）</li></ol><p>编译器中的实现<br></p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// from people.scala</span></span><br><span class="line"><span class="keyword">package</span> tech.mapan.bean</span><br><span class="line"></span><br><span class="line"><span class="keyword">case</span> <span class="class"><span class="keyword">class</span> <span class="title">people</span>(<span class="params">name: <span class="type">String</span>, age: <span class="type">BigInt</span></span>)</span></span><br></pre></td></tr></table></figure><p></p><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// from SparkSQLTest.scala</span></span><br><span class="line"><span class="keyword">package</span> tech.mapan</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.sql.<span class="type">SparkSession</span></span><br><span class="line"><span class="keyword">import</span> tech.mapan.bean.people</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">SparkSQLTest</span> </span>&#123;</span><br><span class="line">  <span class="comment">/**</span></span><br><span class="line"><span class="comment">    * DataFrame、DataSet、rdd之间的转换/ sparkSQL初步应用</span></span><br><span class="line"><span class="comment">    * @param args</span></span><br><span class="line"><span class="comment">    */</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">val</span> spark = <span class="type">SparkSession</span>.builder().appName(<span class="string">"sparkSQL"</span>).master(<span class="string">"local[*]"</span>).getOrCreate()</span><br><span class="line">    <span class="keyword">import</span> spark.implicits._</span><br><span class="line">    <span class="comment">// 从文件创建DataFrame</span></span><br><span class="line">    <span class="keyword">val</span> df = spark.read.json(<span class="string">"./src/main/resources/people.json"</span>)</span><br><span class="line">    df.show</span><br><span class="line"></span><br><span class="line">    <span class="comment">// DataFrame转DataSet</span></span><br><span class="line">    <span class="keyword">val</span> ds = df.as[people]</span><br><span class="line">    ds.show</span><br><span class="line"></span><br><span class="line">    <span class="comment">// DataFrame转rdd</span></span><br><span class="line">    <span class="keyword">val</span> rdd1 = df.rdd</span><br><span class="line">    rdd1.collect().foreach(println)</span><br><span class="line"></span><br><span class="line">    <span class="comment">// DataSet转rdd</span></span><br><span class="line">    <span class="keyword">val</span> rdd2 = ds.rdd</span><br><span class="line">    rdd2.collect().foreach(println)</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 创建临时表</span></span><br><span class="line">    ds.createOrReplaceTempView(<span class="string">"persons"</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">// sql查询年龄超过21岁的人。</span></span><br><span class="line">    spark.sql(<span class="string">"SELECT * FROM persons WHERE age &gt; 21"</span>).show</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// sql查询所有人年龄的和</span></span><br><span class="line">    spark.sql(<span class="string">"SELECT SUM(age) FROM persons"</span>).show</span><br><span class="line">    <span class="comment">// 关闭连接</span></span><br><span class="line">    spark.stop</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div><div class="post-copyright"><p class="copyright-item"><span>原文作者: </span><a href="https://mapan.tech/cn">MaPan</a></p><p class="copyright-item"><span>原文链接: </span><a href="https://mapan.tech/cn/bfb1.html">https://mapan.tech/cn/bfb1.html</a></p><p class="copyright-item"><span>许可协议: </span><a rel="license" href="http://creativecommons.org/licenses/by-nc/4.0/" target="_blank">知识共享署名-非商业性使用 4.0 国际许可协议</a></p></div><footer class="post-footer"><nav class="post-nav"><a class="prev" href="/cn/6b1f.html"><i class="iconfont icon-left"></i> <span class="prev-text nav-default">Frp内网穿透实现minecraft远程联机</span> <span class="prev-text nav-mobile">上一篇</span> </a><a class="next" href="/cn/d275.html"><span class="next-text nav-default">SparkSQL概念</span> <span class="prev-text nav-mobile">下一篇</span> <i class="iconfont icon-right"></i></a></nav></footer></article></div><div class="comments" id="comments"><div id="vcomments"></div></div></div></main><footer id="footer" class="footer"><div class="social-links"><a href="/cn/atom.xml" class="iconfont icon-rss" title="rss" target="_blank"></a></div><div class="copyright"><span class="division">&nbsp;</span><span class="post-count"> 全站字数 80.7k </span><span class="copyright-year">Since 2015 <span class="heart"><i class="iconfont icon-heart"></i> </span><span class="author">MaPan</span></span></div></footer><div class="back-to-top" id="back-to-top"><i class="iconfont icon-up"></i></div></div><script src="./lib/valine/av-min.js?v=3.0.4"></script><script src="./lib/valine/Valine.min.js"></script><script type="text/javascript">new Valine({el:"#vcomments",notify:!1,verify:!0,app_id:"XtxvAXPwOzM9noIc3eyxi3AS-gzGzoHsz",app_key:"yEVQszyxb4bwLuAGU5VHnPR8",placeholder:"说点什么吧...",avatar:"mm",visitor:"ture"})</script><script type="text/javascript" src="/cn/lib/jquery/jquery.min.js"></script><script type="text/javascript" src="/cn/lib/slideout/slideout.js"></script><script type="text/javascript" src="/cn/js/src/even.js?v=2.11.0"></script></body></html>