<!DOCTYPE html><html lang="zh-Hans"><head><meta name="generator" content="Hexo 3.8.0"><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><meta name="theme-color" content="#f8f5ec"><meta name="msapplication-navbutton-color" content="#f8f5ec"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-status-bar-style" content="#f8f5ec"><meta name="referrer" content="same-origin"><meta name="referrer" content="no-referrer"><meta name="description" content="Hive优化"><meta name="keywords" content="大数据,BigData,数据开发,BI,数据分析,Hadoop,Spark,Flink,Hive,HBase"><link rel="alternate" href="/cn/atom.xml" title="马攀的技术栈"><link rel="shortcut icon" type="image/x-icon" href="/cn/favicon.ico?v=2.11.0"><link rel="canonical" href="https://mapan.tech/cn/626f.html"><link rel="stylesheet" type="text/css" href="/cn/css/style.css?v=2.11.0"><script id="baidu_analytics">var _hmt=_hmt||[];!function(){var e=document.createElement("script");e.src="https://hm.baidu.com/hm.js?4ae344ec421c468088f6d7cf68003f4b";var t=document.getElementsByTagName("script")[0];t.parentNode.insertBefore(e,t)}()</script><script id="baidu_push">!function(){var t=document.createElement("script"),s=window.location.protocol.split(":")[0];"https"===s?t.src="https://zz.bdstatic.com/linksubmit/push.js":t.src="http://push.zhanzhang.baidu.com/push.js";var e=document.getElementsByTagName("script")[0];e.parentNode.insertBefore(t,e)}()</script><script>window.config={toc:!0,fancybox:!1,pjax:!1,latex:!1}</script><title>Hive优化 - 马攀的技术栈</title></head><body><div id="mobile-navbar" class="mobile-navbar"><div class="mobile-header-logo"><a href="/cn/." class="logo">马攀的技术栈</a></div><div class="mobile-navbar-icon"><span></span> <span></span> <span></span></div></div><nav id="mobile-menu" class="mobile-menu slideout-menu"><ul class="mobile-menu-list"><a href="/cn/"><li class="mobile-menu-item">首页</li></a><a href="/cn/categories.html"><li class="mobile-menu-item">分类</li></a><a href="/cn/about.html"><li class="mobile-menu-item">关于</li></a><a href="/cn/message.html"><li class="mobile-menu-item">留言</li></a><a href="/cn/links.html"><li class="mobile-menu-item">友链</li></a></ul></nav><div class="container" id="mobile-panel"><header id="header" class="header"><div class="logo-wrapper"><a href="https://mapan.tech" class="logo">马攀的技术栈</a></div><nav class="site-navbar"><ul id="menu" class="menu"><li class="menu-item"><a class="menu-item-link" href="/cn/">首页</a></li><li class="menu-item"><a class="menu-item-link" href="/cn/categories.html">分类</a></li><li class="menu-item"><a class="menu-item-link" href="/cn/about.html">关于</a></li><li class="menu-item"><a class="menu-item-link" href="/cn/message.html">留言</a></li><li class="menu-item"><a class="menu-item-link" href="/cn/links.html">友链</a></li></ul></nav></header><main id="main" class="main"><div class="content-wrapper"><div id="content" class="content"><article class="post"><header class="post-header"><h1 class="post-title">Hive优化</h1><div class="post-meta"><span class="post-time">2020-03-25 </span><span class="post-category"><a href="/cn/categories/数据仓库/">数据仓库</a> </span><span id="/cn/626f.html" class="leancloud-visitors" data-flag-title="Hive优化">阅读数 <span class="leancloud-visitors-count">1000</span> </span><span class="post-count">字数统计 2.3k </span><span class="post-count">阅读时长 8</span></div></header><div class="post-toc" id="post-toc"><h2 class="post-toc-title">文章目录</h2><div class="post-toc-content"><ol class="toc"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-MapJoin"><span class="toc-text">1. MapJoin</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-行列过滤"><span class="toc-text">2. 行列过滤</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-尽量原子化操作"><span class="toc-text">3. 尽量原子化操作</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-采用分区技术"><span class="toc-text">4. 采用分区技术</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-合理设置Map数量和Reduce数"><span class="toc-text">5. 合理设置Map数量和Reduce数</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Map的数量"><span class="toc-text">Map的数量</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Reduce的数量"><span class="toc-text">Reduce的数量</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#6-注意Join的使用"><span class="toc-text">6. 注意Join的使用</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#7-小文件处理"><span class="toc-text">7. 小文件处理</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#8-注意数据倾斜"><span class="toc-text">8. 注意数据倾斜</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#9-合理使用multi-insert，union-all"><span class="toc-text">9. 合理使用multi insert，union all</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#10-Group优化"><span class="toc-text">10.Group优化</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#11-使用压缩"><span class="toc-text">11. 使用压缩</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#12-开启JVM重用"><span class="toc-text">12. 开启JVM重用</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#13-使用动态分区"><span class="toc-text">13.使用动态分区</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#14-使用列式存储"><span class="toc-text">14.使用列式存储</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#15-使用索引"><span class="toc-text">15.使用索引</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#16-利用好EXPLAIN"><span class="toc-text">16.利用好EXPLAIN</span></a></li></ol></div></div><div class="post-content"><p>平常工作中写HiveSQL比较多，对于一些常见的Hive问题和优化做一下总结：</p><h3 id="1-MapJoin"><a href="#1-MapJoin" class="headerlink" title="1. MapJoin"></a>1. MapJoin</h3><p>如果不指定<code>Mapjoin</code>或者不符合<code>MapJoin</code>的条件，那么Hive解析器会将<code>Join</code>操作转换成<code>Common Join</code>, 即在<code>Reduce</code>阶段完成<code>Join</code>，容易发生数据倾斜。这时可以使用MapJoin把小表全部加载到内存中在<code>Map</code>端进行<code>Join</code>，避免<code>Reduce</code>处理。</p><h3 id="2-行列过滤"><a href="#2-行列过滤" class="headerlink" title="2. 行列过滤"></a>2. 行列过滤</h3><p>列处理：在SELECT中，只拿需要处理的列。如非必要，尽量避免SELECT *；</p><p>行处理：尽早的过滤数据，减少每个阶段的数据量，对于分区表尽量使用分区过滤。</p><h3 id="3-尽量原子化操作"><a href="#3-尽量原子化操作" class="headerlink" title="3. 尽量原子化操作"></a>3. 尽量原子化操作</h3><p>尽量避免一个SQL包含复杂的逻辑，可以创建临时表来完成复杂的逻辑。</p><h3 id="4-采用分区技术"><a href="#4-采用分区技术" class="headerlink" title="4. 采用分区技术"></a>4. 采用分区技术</h3><p>可以把数据根据数据量按照天或者按照周、月来分区。</p><h3 id="5-合理设置Map数量和Reduce数"><a href="#5-合理设置Map数量和Reduce数" class="headerlink" title="5. 合理设置Map数量和Reduce数"></a>5. 合理设置Map数量和Reduce数</h3><p>Hive中的SQL查询会生成执行计划，执行计划以MapReduce的方式执行，那么结合数据和集群的大小，Map和Reduce的数量就会影响到SQL的执行效率，除了要控制Hive生成的Job的数量，也要控制map和reduce的数量。</p><h4 id="Map的数量"><a href="#Map的数量" class="headerlink" title="Map的数量"></a>Map的数量</h4><p>通常情况下，作业会通过input的目录产生一个或者多个map任务。<br>主要决定因素有：input的文件总个数，input的文件大小，集群设置的文件块大小。<br>Hive中默认的<code>hive.input.format</code>是<code>org.apache.hadoop.hive.ql.io.CombineHivelnputFormat</code>，对于<code>combineHiveInputFormat</code>，它的输入的map数量由三个配置决定：<br><code>mapred.min.split.size.per.node</code> 一个节点上split的至少的大小<br><code>mapred.min.split.size.per.rack</code> 一个交换机下split 至少的大小<br><code>mapred.max.split.size</code> 一个split 最大的大小<br>主要思路是把输入目录下的大文件分成多个map的输入，并合并小文件，做为一个map的输入<br>具体的原理是下述三步：</p><p>a) 根据输入目录下的每个文件，如果其长度超过<code>mapred.max.split.size</code>，以Block 为单位分成多个Split（一个Split是一个map的输入），每个split的长度都大于<code>mapred.max.split.size</code>，因为以Block为单位，因此也会大于·<code>BlockSize</code>，此文件剩下的长度如果大于<code>mapred.min.split.size.per.node</code>，则生成一个Split，否则先暂时保留；</p><p>b) 现在剩下的都是一些长度较短的碎片，把每个rack 下碎片合并，只要长度超过<br><code>mapred.max.split.size</code>就合并成一-个 split，最后如果剩下的碎片比<code>mapred.min.split.size.per.rack</code> 大，就合并成一个split，否则暂时保留；</p><p>c) 把不同rack下的碎片合并，只要长度超过<code>mapred.max.split.size</code>就合并成一个 split，剩下的碎片无论长度，合并成一个split。</p><h4 id="Reduce的数量"><a href="#Reduce的数量" class="headerlink" title="Reduce的数量"></a>Reduce的数量</h4><p>reduce数量由以下三个参数决定：</p><ul><li><code>mapred.reduce.tasks</code>（强制指定reduce的任务数量）</li><li><code>hive.exec.reducers.bytes.per.reducer</code>（每个reduce任务处理的数据量，默认为1000^3=1G）</li><li><code>hive.exec.reducers.max</code>（每个任务最大的reduce数，默认为999）<br>计算reducer 数的公式:<br><code>N=min(hive.exec.reducers.max，总输入数据量/hive.exec.reducers.bytes.per.reducer)</code></li></ul><h3 id="6-注意Join的使用"><a href="#6-注意Join的使用" class="headerlink" title="6. 注意Join的使用"></a>6. 注意Join的使用</h3><p>把重复关联键少的表放在join前面，可以提高join效率。网上所谓的<code>hive会将join前面的表放在内存中，把小表放在前面能减少内存资源消耗</code>这种说法在现在看来其实是有异议的。用1条记录的表和3亿条记录的表做join，无论小表是放在join的前面还是join的后面，执行的时间几乎都是相同的，原因是因为Hive在早期某个版本中，底层对此进行了优化。</p><h3 id="7-小文件处理"><a href="#7-小文件处理" class="headerlink" title="7. 小文件处理"></a>7. 小文件处理</h3><p><code>HiveInputFormat</code>没有对小文件的合并功能<br>可以使用<code>Combinefileinputformat</code>，将多个小文件打包作为一个整体的inputsplit，减少map任务数<br><code>set mapred.max.split.size=256000000</code>;<br><code>set mapred.min.split.size.per.node= 256000000</code>；<br><code>set mapred.min.split.size.per.rack=256000000</code>;<br><code>set hive.input.format=org.apache.hadoop.hive.ql.io.CombineHivelnputFormat</code>;</p><p>设置hive参数，额外启动-一个MR Job打包小文件:<br><code>hive.merge.mapredfiles=false</code> 是否合并Reduce 输出文件，默认为False<br><code>hive.merge.size.per.task = 256*1000*1000</code> 合并文件的大小</p><h3 id="8-注意数据倾斜"><a href="#8-注意数据倾斜" class="headerlink" title="8. 注意数据倾斜"></a>8. 注意数据倾斜</h3><p>a) 通过 <code>hive.groupby.skewindata=true</code>控制生成两个MR Job，第一个 MR Job Map的输出结果随机分配到reduce做次预汇总，减少某些key值条数过多某些key条数过小造成的数据倾斜问题；</p><p>b) 通过<code>hive.map.aggr = true</code>（默认为true）在Map端做combiner，假如map各条数据基本上不一样，聚合没什么意义，做combiner反而画蛇添足，hive里也考虑的比较周到通过参数<br><code>hive.groupby.mapaggr.checkinterval = 100000</code>（默认）</p><p><code>hive.map.aggr.hash.min.reduction=0.5</code>（默认），预先取100000条数据聚合，如果聚合后的条数/100000&gt;0.5，则不再聚合。</p><h3 id="9-合理使用multi-insert，union-all"><a href="#9-合理使用multi-insert，union-all" class="headerlink" title="9. 合理使用multi insert，union all"></a>9. 合理使用multi insert，union all</h3><p><code>multi insert</code>适合基于同一个源表按照不同逻辑不同粒度处理插入不同表的场景，做到只需要扫描源表一次，job个数不变，减少源表扫描次数；</p><p>union all用好，可减少表的扫描次数，减少job 的个数，通常预先按不同逻辑不同条件生成的查询<code>union all</code>后，再统一<code>Group by</code>计算，不同表的<code>union all</code>相当于<code>multiple inputs</code>，同一个表的<code>union all</code>，相当map一次输出多条。</p><h3 id="10-Group优化"><a href="#10-Group优化" class="headerlink" title="10.Group优化"></a>10.Group优化</h3><p>对于Group操作，首先在map端聚合，最后在reduce端做聚合，以下是相关的参数:<br><code>hive.map.aggr=true</code>是否在Map端进行聚合，默认为True,<br><code>hive.groupby.mapaggr.checkinterval= 100000</code>在Map端进行聚合操作的条目数目。</p><h3 id="11-使用压缩"><a href="#11-使用压缩" class="headerlink" title="11. 使用压缩"></a>11. 使用压缩</h3><p>设置map端输出，中间结果压缩。不完全解决数据倾斜问题，但是减少了IO读写和网络传输，能提高很多效率。</p><p><code>set hive.exec.compress.intermediate = true;</code></p><p>对于中间数据压缩，选择一个低CPU开销的Codec要比选择一个压缩率高的Codec要重要的多。</p><p><code>SnappyCodec</code>是一个比较好的中间文件Codec，因为其很好的结合了低CPU开销和好的压缩执行效率。</p><h3 id="12-开启JVM重用"><a href="#12-开启JVM重用" class="headerlink" title="12. 开启JVM重用"></a>12. 开启JVM重用</h3><p>JVM重用是Hadoop调优参数的内容，对hive的性能具有非常大的影响，特别是对于很难避免小文件的场景或者Task特别多的场景，这类场景大多数执行时间都很短。Hadoop默认配置是使用JVM来执行map和reduce任务的，这时Jvm的启动过程可能会造成相当大的开销，尤其是执行的job包含有成千上万个task任务的情况。</p><p>JVM重用可以使得JVM实例在同一个JOB中重新使用N次，N的值可以在<code>Hadoop的mapre-site.xml</code>文件中进行设置<br><code>mapred.job.reuse.jvm.num.tasks</code><br>也可在hive的执行设置：<br><code>set mapred.job.reuse.jvm.num.tasks=10</code>;</p><p>JVM重用的一个缺点是，开启JVM重用将会一直占用使用到的task插槽，以便进行重用，直到任务完成后才能释放。如果某个不平衡的job中有几个<code>reduce task</code> 执行的时间要比其他<code>reduce task</code>消耗的时间多得多的话，那么保留的插槽就会一直空闲着却无法被其他的job使用，直到所有的task都结束了才会释放。</p><h3 id="13-使用动态分区"><a href="#13-使用动态分区" class="headerlink" title="13.使用动态分区"></a>13.使用动态分区</h3><p>在Hive中，有时候会希望根据输入的Key，把结果自动输出到不同的目录中，这可以通过动态分区来实现，就是把每一个 key当作一个 分区。<br>如果要启动动态分区，则需要进行下面的设置首先需要在hive语句中设置允许动态分区<br><code>set hive.exec.dynamic.partition=true</code>；<br><code>set hive.exec.dynamic.partition.mode=nonstrict</code>；<br>在动态分区有可能很大的情况下，还需要其他的调整<br><code>hive.exec.dynamic.partitions.pernode</code> 参数指的是每个节点上能够生成的最大分区，这个在最坏情况下应该是跟最大分区一样的值<br><code>hive.exec.dynamic.partitions.partitions</code> 参数指的是总共的最大的动态分区数<code>hive.exec.max.createdfiles</code>参数指的是能够创建的最多文件数（分区一多，文件必然就多了）<br>最后要注意的是select语句中要把distribute的key也select出来。</p><h3 id="14-使用列式存储"><a href="#14-使用列式存储" class="headerlink" title="14.使用列式存储"></a>14.使用列式存储</h3><p>根据数据的特点来进行技术选型：如果数据结构是比较扁平的，那么用<code>ORC</code> 比较合适，如果嵌套较多，就用 <code>Parquet</code>。<br>列存储主要有两个好处：数据压缩和查询性能提升，在节省了存储的同时还提升了查询性能，这个的收益是非常可观的。</p><h3 id="15-使用索引"><a href="#15-使用索引" class="headerlink" title="15.使用索引"></a>15.使用索引</h3><p>索引可以避免全表扫描和资源浪费<br>索引可以加快含有Group By语句的查询的计算速度<br><code>hive.optimize.index.filter=true</code>; 使用自动索引<br><code>hive.optimie.index.groupby=true</code>;使用聚合索引优化GROUP BY操作</p><h3 id="16-利用好EXPLAIN"><a href="#16-利用好EXPLAIN" class="headerlink" title="16.利用好EXPLAIN"></a>16.利用好EXPLAIN</h3><p>Explain命令对于优化查询语句很重要，针对某些查询语句，我们可以通过它查看各个执行计划，针对耗时的地方，采取优化。</p></div><div class="post-copyright"><p class="copyright-item"><span>原文作者: </span><a href="https://mapan.tech/cn">MaPan</a></p><p class="copyright-item"><span>原文链接: </span><a href="https://mapan.tech/cn/626f.html">https://mapan.tech/cn/626f.html</a></p><p class="copyright-item"><span>许可协议: </span><a rel="license" href="http://creativecommons.org/licenses/by-nc/4.0/" target="_blank">知识共享署名-非商业性使用 4.0 国际许可协议</a></p></div><footer class="post-footer"><nav class="post-nav"><a class="prev" href="/cn/f16a.html"><i class="iconfont icon-left"></i> <span class="prev-text nav-default">记录一次Hive中遇到的问题</span> <span class="prev-text nav-mobile">上一篇</span> </a><a class="next" href="/cn/a77d.html"><span class="next-text nav-default">二分查找</span> <span class="prev-text nav-mobile">下一篇</span> <i class="iconfont icon-right"></i></a></nav></footer></article></div><div class="comments" id="comments"><div id="vcomments"></div></div></div></main><footer id="footer" class="footer"><div class="social-links"><a href="/cn/atom.xml" class="iconfont icon-rss" title="rss" target="_blank"></a></div><div class="copyright"><span class="division">&nbsp;</span><span class="post-count"> 全站字数 80.7k </span><span class="copyright-year">Since 2015 <span class="heart"><i class="iconfont icon-heart"></i> </span><span class="author">MaPan</span></span></div></footer><div class="back-to-top" id="back-to-top"><i class="iconfont icon-up"></i></div></div><script src="./lib/valine/av-min.js?v=3.0.4"></script><script src="./lib/valine/Valine.min.js"></script><script type="text/javascript">new Valine({el:"#vcomments",notify:!1,verify:!0,app_id:"XtxvAXPwOzM9noIc3eyxi3AS-gzGzoHsz",app_key:"yEVQszyxb4bwLuAGU5VHnPR8",placeholder:"说点什么吧...",avatar:"mm",visitor:"ture"})</script><script type="text/javascript" src="/cn/lib/jquery/jquery.min.js"></script><script type="text/javascript" src="/cn/lib/slideout/slideout.js"></script><script type="text/javascript" src="/cn/js/src/even.js?v=2.11.0"></script></body></html>